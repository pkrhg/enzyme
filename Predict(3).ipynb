{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model('enzyme_rnn_v3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "inputs=pd.read_csv('inputs.csv')\n",
    "gt=pd.read_csv('gt.csv')\n",
    "batch=inputs.join(gt)\n",
    "batch.columns=['Amino acid', 'Class']\n",
    "x=batch['Amino acid']\n",
    "y=batch['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 amino acids processed.\n",
      "100 amino acids processed.\n",
      "150 amino acids processed.\n",
      "200 amino acids processed.\n",
      "250 amino acids processed.\n",
      "300 amino acids processed.\n",
      "350 amino acids processed.\n",
      "400 amino acids processed.\n",
      "450 amino acids processed.\n"
     ]
    }
   ],
   "source": [
    "#Data preprocessing\n",
    "import urllib.request\n",
    "import warnings\n",
    "import numpy as np\n",
    "from Bio import PDB\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "counter = 0\n",
    "sequences = np.array([])\n",
    "failed = np.array([])\n",
    "short = np.array([])\n",
    "for x in batch['Amino acid']:\n",
    "    counter += 1\n",
    "    urllib.request.urlretrieve(\"http://files.rcsb.org/download/\" + x +\".pdb\", x + \".pdb\")\n",
    "    parser=PDB.PDBParser()\n",
    "    struct=parser.get_structure(x,x + '.pdb')\n",
    "    atom=list(struct.get_atoms())[0]\n",
    "    pp=PDB.PPBuilder()\n",
    "    polypeptide=pp.build_peptides(struct)\n",
    "    if len(polypeptide) == 0:\n",
    "        failed = np.append(failed, counter-1)\n",
    "        #print(\"Amino acid \" + x + \" not parsed correctly.\")\n",
    "    elif len(polypeptide) > 0:\n",
    "        polypeptide=polypeptide[0]\n",
    "        sequence=polypeptide.get_sequence()\n",
    "        if len(str(sequence)) < 50:\n",
    "            short = np.append(short, counter-1)\n",
    "            #print(\"Amino acid \" + x + \"too short.\")\n",
    "        else:\n",
    "            sequences = np.append(sequences, str(sequence))\n",
    "    if counter % 50 == 0:\n",
    "        print(counter, \"amino acids processed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def int_concatenate(sequence):\n",
    "    vals = []\n",
    "    for a in sequence:\n",
    "        seq = [ord(x) for x in a]\n",
    "        seq = [seq]\n",
    "        vals += seq\n",
    "    return vals \n",
    "intvalues = int_concatenate(sequences)\n",
    "dropped = batch\n",
    "fail = np.append(failed, short)\n",
    "fail = np.sort(fail)\n",
    "fail = np.flip(fail)\n",
    "for x in fail:\n",
    "    dropped = dropped.drop(dropped.index[int(x)], axis=0)\n",
    "dropped['Sequence'] = sequences\n",
    "x = np.array(intvalues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predicting, and adjusting results to integer label values\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder=OneHotEncoder()\n",
    "encoder.fit(np.array(list(x[0])).reshape(-1,1)) \n",
    "x=np.array([encoder.transform(np.array(list(item[:50])).reshape(-1,1)).toarray() for item in x])\n",
    "y_prob = model.predict(x) \n",
    "y_classes = y_prob.argmax(axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 3, 3, 3, 1, 1, 2, 5, 2, 4, 4, 1, 3, 2, 4, 3, 3, 3, 3, 1, 3, 1,\n",
       "       2, 1, 2, 1, 2, 3, 1, 2, 1, 2, 3, 1, 2, 2, 2, 1, 3, 1, 3, 3, 2, 1,\n",
       "       3, 4, 1, 1, 2, 1, 3, 3, 2, 3, 2, 3, 4, 1, 1, 1, 5, 3, 2, 2, 2, 3,\n",
       "       1, 1, 1, 3, 2, 1, 3, 3, 1, 3, 3, 3, 6, 1, 4, 1, 1, 3, 2, 2, 3, 2,\n",
       "       3, 3, 1, 3, 1, 2, 2, 4, 2, 3, 1, 1, 1, 3, 1, 3, 2, 5, 4, 1, 3, 3,\n",
       "       1, 2, 3, 3, 3, 2, 2, 1, 3, 3, 3, 2, 1, 3, 2, 1, 1, 1, 1, 3, 6, 1,\n",
       "       3, 1, 1, 3, 2, 3, 2, 1, 3, 3, 1, 1, 3, 3, 2, 5, 2, 1, 1, 1, 3, 1,\n",
       "       3, 1, 4, 2, 2, 2, 3, 1, 1, 3, 3, 1, 3, 2, 3, 2, 3, 2, 1, 1, 3, 2,\n",
       "       2, 3, 1, 3, 2, 3, 2, 3, 2, 2, 2, 2, 3, 2, 3, 5, 1, 3, 3, 2, 3, 1,\n",
       "       1, 2, 1, 3, 3, 2, 2, 3, 3, 3, 1, 2, 1, 3, 2, 2, 4, 1, 3, 3, 1, 2,\n",
       "       2, 1, 1, 2, 3, 2, 4, 1, 3, 2, 2, 4, 1, 3, 1, 5, 2, 3, 3, 1, 2, 5,\n",
       "       3, 3, 2, 4, 6, 1, 3, 1, 1, 1, 3, 1, 3, 2, 2, 3, 2, 1, 1, 3, 3, 3,\n",
       "       1, 3, 2, 3, 1, 3, 1, 1, 6, 1, 2, 3, 2, 2, 2, 1, 2, 2, 2, 6, 1, 2,\n",
       "       1, 3, 3, 3, 1, 2, 3, 3, 2, 3, 3, 3, 3, 2, 3, 3, 1, 3, 3, 3, 3, 1,\n",
       "       2, 1, 1, 1, 1, 3, 2, 2, 1, 3, 2, 5, 1, 1, 3, 2, 1, 3, 2, 1, 3, 1,\n",
       "       3, 3, 3, 5, 3, 2, 3, 3, 2, 1, 3, 2, 1, 2, 3, 4, 1, 6, 2, 3, 3, 2,\n",
       "       3, 6, 3, 2, 1, 3, 3, 3, 2, 2, 4, 3, 2, 3, 1, 1, 1, 3, 3, 2, 3, 2,\n",
       "       2, 3, 3, 3, 4, 1, 1, 2, 2, 5, 3, 5, 3, 3, 3, 2, 3, 2, 2, 1, 3, 3,\n",
       "       3, 1, 3, 1, 2, 1, 1, 3, 3, 1, 3, 1, 2, 3, 1, 2, 1, 2, 3, 3, 1, 2,\n",
       "       2, 2, 2, 1, 1, 2, 3, 1, 1, 2, 3])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_classes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
